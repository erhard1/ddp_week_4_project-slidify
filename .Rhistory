## <102/48/150>
training_iris <-training(split_iris)
head(training_iris)
##    Sepal.Length Sepal.Width Petal.Length Petal.Width Species
## 1           5.1         3.5          1.4         0.2  setosa
## 7           4.6         3.4          1.4         0.3  setosa
## 8           5.0         3.4          1.5         0.2  setosa
## 9           4.4         2.9          1.4         0.2  setosa
## 10          4.9         3.1          1.5         0.1  setosa
## 11          5.4         3.7          1.5         0.2  setosa
count(training_iris, Species)
##      Species  n
## 1     setosa 35
## 2 versicolor 35
## 3  virginica 30
testing_iris <-testing(split_iris)
head(testing_iris)
##    Sepal.Length Sepal.Width Petal.Length Petal.Width Species
## 2           4.9         3.0          1.4         0.2  setosa
## 3           4.7         3.2          1.3         0.2  setosa
## 4           4.6         3.1          1.5         0.2  setosa
## 5           5.0         3.6          1.4         0.2  setosa
## 6           5.4         3.9          1.7         0.4  setosa
## 14          4.3         3.0          1.1         0.1  setosa
count(testing_iris, Species)
library(lubridate)
url <- "http://bit.ly/raw-train-data-csv"
all_stations <-
# Step 1: Read in the data.
read_csv(url) %>%
# Step 2: filter columns and rename stationname
dplyr::select(station = stationname, date, rides) %>%
# Step 3: Convert the character date field to a date encoding.
# Also, put the data in units of 1K rides
mutate(date = mdy(date), rides = rides / 1000) %>%
# Step 4: Summarize the multiple records using the maximum.
group_by(date, station) %>%
summarize(rides = max(rides), .groups = "drop")
View(all_stations)
install.packages("modeldata")
data(crickets, package = "modeldata")
names(crickets)
#> [1] "species" "temp"    "rate"
# Plot the temperature on the x-axis, the chirp rate on the y-axis. The plot
# elements will be colored differently for each species:
ggplot(crickets, aes(x = temp, y = rate, col = species)) +
# Plot points for each data point and color by species
geom_point() +
# Show a simple linear model fit created separately for each species:
geom_smooth(method = lm, se = FALSE) +
labs(x = "Temperature (C)", y = "Chirp Rate (per minute)")
library(tidyverse)
data(crickets, package = "modeldata")
names(crickets)
#> [1] "species" "temp"    "rate"
# Plot the temperature on the x-axis, the chirp rate on the y-axis. The plot
# elements will be colored differently for each species:
ggplot(crickets, aes(x = temp, y = rate, col = species)) +
# Plot points for each data point and color by species
geom_point() +
# Show a simple linear model fit created separately for each species:
geom_smooth(method = lm, se = FALSE) +
labs(x = "Temperature (C)", y = "Chirp Rate (per minute)")
View(crickets)
interaction_fit <-  lm(rate ~ (temp + species)^2, data = crickets)
# To print a short summary of the model:
interaction_fit
par(mfrow = c(1, 2))
# Show residuals vs predicted values:
plot(interaction_fit, which = 1)
# A normal quantile plot on the residuals:
plot(interaction_fit, which = 2)
main_effect_fit <-  lm(rate ~ temp + species, data = crickets)
# Compare the two:
anova(main_effect_fit, interaction_fit)
library(tidymodels)
parsnip:::parsnip_addin()
install.packages("gutenbergr")
wuthering_heights <- gutenberg_download(768,
files = f768,
mirror = "http://aleph.gutenberg.org")
library(gutenbergr)
wuthering_heights <- gutenberg_download(768,
files = f768,
mirror = "http://aleph.gutenberg.org")
text <- gutenberg_download(84)
View(text)
library(AppliedPredictiveModeling)
data("segmentationOriginal")
View(segmentationOriginal)
library(caret)
library(tidyverse)
##Problem 1
testing_01 <- segmentationOriginal %>%
filter(case == 'test')
##Problem 1
testing_01 <- segmentationOriginal %>%
filter(Case == 'test')
##Problem 1
testing_01 <- segmentationOriginal %>%
filter(Case == 'Test')
training_01 <- segmentationOriginal %>%
filter(Case == 'Train')
seed(125)
set.seed(125)
segmentationOriginal %>% is.na()
count(segmentationOriginal %>% is.na())
library(tidymodels)
data(scat, package = "modeldata")
View(scat)
scat_rec <-
recipe(Species ~ Location + Age + Mass + Diameter, data = scat) %>%
step_dummy(all_nominal(), one_hot = TRUE) %>%
prep()
View(scat_rec)
scat_rec %>%
bake(new_data = NULL) %>%
names()
scat_rec <-
recipe(Species ~ Location + Age + Mass + Diameter, data = scat) %>%
step_dummy(all_nominal(), one_hot = TRUE) %>%
prep()
scat_rec %>%
bake(new_data = NULL) %>%
names()
scat_rec <-
recipe(Species ~ Location + Age + Mass + Diameter, data = scat) %>%
step_dummy(all_nominal(), one_hot = TRUE) %>%
prep()
scat_rec %>%
bake(new_data = NULL) %>%
names()
scat_rec <-
recipe(Species ~ Location + Age + Mass + Diameter, data = scat) %>%
step_dummy(all_nominal_predictors(), one_hot = TRUE) %>%
prep()
scat_rec %>%
bake(new_data = NULL) %>%
names()
scat_rec <-
recipe(Species ~ Location + d13C + d15N + CN, data = scat) %>%
step_impute_mean(d13C, d15N, CN) %>%
step_dummy(all_nominal_predictors(), one_hot = TRUE) %>%
step_pca(d13C, d15N, CN, keep_original_cols = TRUE) %>%
prep()
scat_rec %>%
bake(new_data = scat) %>%
names()
scat_rec <-
recipe(Species ~ Location + d13C + d15N + CN, data = scat) %>%
step_impute_knn(d13C, d15N, CN) %>%
step_dummy(all_nominal_predictors(), one_hot = TRUE) %>%
step_pca(d13C, d15N, CN, keep_original_cols = TRUE) %>%
prep()
scat_rec %>%
bake(new_data = scat) %>%
names()
View(scat_rec)
scat_rec <-
recipe(Species ~ Location + d13C + d15N + CN, data = scat) %>%
step_impute_knn(d13C, d15N, CN) %>%
imputed_scat <-
bake(scat_rec, new_data = scat)
scat_rec <-
recipe(Species ~ Location + d13C + d15N + CN, data = scat) %>%
step_impute_knn(d13C, d15N, CN)
imputed_scat <-
bake(scat_rec, new_data = scat)
scat_rec <-
recipe(Species ~ Location + d13C + d15N + CN, data = scat) %>%
step_impute_knn(d13C, d15N, CN) %>%
prep()
imputed_scat <-
bake(scat_rec, new_data = scat)
View(imputed_scat)
scat_rec <-
recipe(Species ~ Location + d13C + d15N + CN, data = scat) %>%
step_impute_knn(all_predictors(), neighbors = 7) %>%
prep()
imputed_scat <-
bake(scat_rec, new_data = scat)
View(imputed_scat)
scat_rec <-
recipe(Species ~ Location + d13C + d15N + CN, data = scat) %>%
step_impute_knn(all_predictors(), neighbors = 7, id = rand_id("impute_knn")) %>%
prep()
imputed_scat <-
bake(scat_rec, new_data = scat)
tidy(scat_rec, number = 1)
tidy(scat_rec, number = 2)
tidy(scat_rec, number = 1)
scat_rec <-
recipe(Species ~ ., data = scat) %>%
step_impute_knn(all_predictors(), neighbors = 7, id = rand_id("impute_knn")) %>%
prep()
imputed_scat <-
bake(scat_rec, new_data = scat)
new_scat <- scat %>%
mutate(imputed = if_else(is.na(), 'yes', 'no'))
model_fit <- train(class ~., data = training_01, method = 'rpart')
View(testing_01)
View(training_01)
str(training_01)
model_fit <- train(Class ~., data = training_01, method = 'rpart')
model_fit
predict_test <- predict(model_fit, newdata = testing_01)
confusionMatrix(testing_01$Class, predict_test$Class)
confusionMatrix(testing_01$Class, predict_test)
dim(segmentationOriginal)
orig_names <- names(segmentationOriginal)
dummy_rows <- training_01 %>%
add_row(TotalIntench2 = 23,000, FiberWidthCh1 = 10, PerimStatusCh1=2)
dummy_rows <- training_01 %>%
add_row(TotalIntench2 = 23000, FiberWidthCh1 = 10, PerimStatusCh1=2)
dummy_rows <- training_01 %>%
add_row(TotalIntenCh2 = 23000, FiberWidthCh1 = 10, PerimStatusCh1=2)
View(dummy_rows)
dummy_rows <- training_01 %>%
add_row(TotalIntenCh2 = 23000, FiberWidthCh1 = 10, PerimStatusCh1=2) %>%
add_row(TotalIntenCh2 = 50000, FiberWidthCh1 = 10, VarIntenCh4 = 100) %>%
add_row(TotalIntenCh2 = 57000, FiberWidthCh1 = 8, VarIntenCh4 = 100) %>%
add_row(FiberWidthCh1 = 8, VarIntenCh4 = 100, PerimStatusCh1=2)
dummy_rows <- training_01 %>%
add_row(Cell = 1, TotalIntenCh2 = 23000, FiberWidthCh1 = 10, PerimStatusCh1=2) %>%
add_row(Cell = 2, TotalIntenCh2 = 50000, FiberWidthCh1 = 10, VarIntenCh4 = 100) %>%
add_row(Cell = 3, TotalIntenCh2 = 57000, FiberWidthCh1 = 8, VarIntenCh4 = 100) %>%
add_row(Cell = 4, FiberWidthCh1 = 8, VarIntenCh4 = 100, PerimStatusCh1=2)
model_fit <- train(Class ~ AngleCh1:YCentroid, data = training_01, method = 'rpart')
model_fit
model_fit <- train(Class ~ ., data = training_01, method = 'rpart')
model_fit
model_fit <- train(Class ~ ., data = training_01[,c(-1,-2)], method = 'rpart')
model_fit
library(tidymodels)
impute_rec <-
recipe(Class ~ ., data = scat[,c(-1,-2)]) %>%
step_impute_knn(all_predictors(), neighbors = 5, id = rand_id("impute_knn")) %>%
prep()
impute_rec <-
recipe(Class ~ ., data = dummy_rows[,c(-1,-2)]) %>%
step_impute_knn(all_predictors(), neighbors = 5, id = rand_id("impute_knn")) %>%
prep()
warnings()
imputed_data <-
bake(impute_rec, new_data = dummy_rows[,c(-1,-2)]))
imputed_data <-
bake(impute_rec, new_data = dummy_rows[,c(-1,-2)])
View(imputed_data)
quiz_data <- imputed_data %>%
filter(top_n(-4))
quiz_data <- imputed_data %>%
top_n(-4)
View(quiz_data)
quiz_data <- imputed_data[1010:1013,]
View(quiz_data)
training_01 <- training_01 %>%
select(-1, -2)
testing_01 <- testing_01 %>%
select(-1, -2)
testing_01 <- segmentationOriginal %>%
filter(Case == 'Test')
training_01 <- segmentationOriginal %>%
filter(Case == 'Train')
training_01 <- training_01 %>%
select(-1, -2)
testing_01 <- testing_01 %>%
select(-1, -2)
set.seed(125)
model_fit <- train(Class ~ ., data = training_01, method = 'rpart')
model_fit
predict_test <- predict(model_fit, newdata = testing_01)
confusionMatrix(testing_01$Class, predict_test)
dim(segmentationOriginal)
orig_names <- names(segmentationOriginal)
dummy_rows <- training_01 %>%
add_row(Cell = 1, TotalIntenCh2 = 23000, FiberWidthCh1 = 10, PerimStatusCh1=2) %>%
add_row(Cell = 2, TotalIntenCh2 = 50000, FiberWidthCh1 = 10, VarIntenCh4 = 100) %>%
add_row(Cell = 3, TotalIntenCh2 = 57000, FiberWidthCh1 = 8, VarIntenCh4 = 100) %>%
add_row(Cell = 4, FiberWidthCh1 = 8, VarIntenCh4 = 100, PerimStatusCh1=2)
impute_rec <-
recipe(Class ~ ., data = dummy_rows) %>%
step_impute_knn(all_predictors(), neighbors = 5) %>%
prep()
imputed_data <-
bake(impute_rec, new_data = dummy_rows[,c(-1,-2)])
quiz_data <- imputed_data[1010:1013,]
predict_quiz <- predict(model_fit, newdata = quiz_data)
testing_01 <- segmentationOriginal %>%
filter(Case == 'Test')
training_01 <- segmentationOriginal %>%
filter(Case == 'Train')
training_01 <- training_01 %>%
select(-1, -2)
testing_01 <- testing_01 %>%
select(-1, -2)
set.seed(125)
model_fit <- train(Class ~ ., data = training_01, method = 'rpart')
model_fit
predict_test <- predict(model_fit, newdata = testing_01)
confusionMatrix(testing_01$Class, predict_test)
dim(segmentationOriginal)
orig_names <- names(segmentationOriginal)
dummy_rows <- training_01 %>%
add_row(Cell = 1, TotalIntenCh2 = 23000, FiberWidthCh1 = 10, PerimStatusCh1=2) %>%
add_row(Cell = 2, TotalIntenCh2 = 50000, FiberWidthCh1 = 10, VarIntenCh4 = 100) %>%
add_row(Cell = 3, TotalIntenCh2 = 57000, FiberWidthCh1 = 8, VarIntenCh4 = 100) %>%
add_row(Cell = 4, FiberWidthCh1 = 8, VarIntenCh4 = 100, PerimStatusCh1=2)
impute_rec <-
recipe(Class ~ ., data = dummy_rows) %>%
step_impute_knn(all_predictors(), neighbors = 5) %>%
prep()
imputed_data <-
bake(impute_rec, new_data = dummy_rows)
quiz_data <- imputed_data[1010:1013,]
predict_quiz <- predict(model_fit, newdata = quiz_data)
predict_quiz
tidy(predict_quiz)
print(predict_quiz)
impute_rec <-
recipe(Class ~ ., data = dummy_rows) %>%
step_impute_mean(all_numeric_predictors()) %>%
prep()
imputed_data <-
bake(impute_rec, new_data = dummy_rows)
quiz_data <- imputed_data[1010:1013,]
predict_quiz <- predict(model_fit, newdata = quiz_data)
testing_01 <- segmentationOriginal %>%
filter(Case == 'Test')
training_01 <- segmentationOriginal %>%
filter(Case == 'Train')
training_01 <- training_01 %>%
select(-1, -2)
testing_01 <- testing_01 %>%
select(-1, -2)
set.seed(125)
model_fit <- train(Class ~ ., data = training_01, method = 'rpart')
model_fit
predict_test <- predict(model_fit, newdata = testing_01)
confusionMatrix(testing_01$Class, predict_test)
dim(segmentationOriginal)
orig_names <- names(segmentationOriginal)
dummy_rows <- training_01 %>%
add_row(Cell = 1, TotalIntenCh2 = 23000, FiberWidthCh1 = 10, PerimStatusCh1=2) %>%
add_row(Cell = 2, TotalIntenCh2 = 50000, FiberWidthCh1 = 10, VarIntenCh4 = 100) %>%
add_row(Cell = 3, TotalIntenCh2 = 57000, FiberWidthCh1 = 8, VarIntenCh4 = 100) %>%
add_row(Cell = 4, FiberWidthCh1 = 8, VarIntenCh4 = 100, PerimStatusCh1=2)
## impute_rec <-
##         recipe(Class ~ ., data = dummy_rows) %>%
##         step_impute_knn(all_predictors(), neighbors = 5) %>%
##         prep()
impute_rec <-
recipe(Class ~ ., data = dummy_rows) %>%
step_impute_mean(all_numeric_predictors()) %>%
prep()
imputed_data <-
bake(impute_rec, new_data = dummy_rows)
quiz_data <- imputed_data[1010:1013,]
predict_quiz <- predict(model_fit, newdata = quiz_data)
testing_01 <- segmentationOriginal %>%
filter(Case == 'Test')
training_01 <- segmentationOriginal %>%
filter(Case == 'Train')
training_01 <- training_01 %>%
select(-1, -2)
testing_01 <- testing_01 %>%
select(-1, -2)
set.seed(125)
model_fit <- train(Class ~ ., data = training_01, method = 'rpart')
model_fit
predict_test <- predict(model_fit, newdata = testing_01)
confusionMatrix(testing_01$Class, predict_test)
dim(segmentationOriginal)
orig_names <- names(segmentationOriginal)
dummy_rows <- training_01 %>%
add_row(TotalIntenCh2 = 23000, FiberWidthCh1 = 10, PerimStatusCh1=2) %>%
add_row(TotalIntenCh2 = 50000, FiberWidthCh1 = 10, VarIntenCh4 = 100) %>%
add_row(TotalIntenCh2 = 57000, FiberWidthCh1 = 8, VarIntenCh4 = 100) %>%
add_row(FiberWidthCh1 = 8, VarIntenCh4 = 100, PerimStatusCh1=2)
## impute_rec <-
##         recipe(Class ~ ., data = dummy_rows) %>%
##         step_impute_knn(all_predictors(), neighbors = 5) %>%
##         prep()
impute_rec <-
recipe(Class ~ ., data = dummy_rows) %>%
step_impute_mean(all_numeric_predictors()) %>%
prep()
imputed_data <-
bake(impute_rec, new_data = dummy_rows)
quiz_data <- imputed_data[1010:1013,]
predict_quiz <- predict(model_fit, newdata = quiz_data)
predict_quiz
df_dummy_impute_mean <- data.frame(
sapply(
dummy_rows,
function(x) ifelse(is.na(x),
mean(x, na.rm = TRUE),
x)))
df_dummy_impute_mean <- data.frame(
sapply(
dummy_rows,
function(x) ifelse(is.na(x), mean(x, na.rm = TRUE), x)))
df_dummy_impute_mean <- data.frame(
sapply(
dummy_rows[,-1],
function(x) ifelse(is.na(x), mean(x, na.rm = TRUE), x)))
View(df_dummy_impute_mean)
df_dummy <- df_dummy_impute_mean[1010:1013,]
View(df_dummy)
View(quiz_data)
predict(model_fit, newdata = df_dummy)
plot(model_fit)
plot(model_fit$finalModel)
textt(model_fit$finalModel)
text(model_fit$finalModel)
install.packages("pgmm")
library(pgmm)
data(olive)
View(olive)
table(olive)
olive <- olive[,-1]
newdata <- as.data.frame(t(colMeans(olive)))
View(newdata)
model_fit<- train(Area~., data=olive, method='rpart')
pred_fit<- predict(model_fit, newdata = olive)
predict_quiz<- predict(model_fit, newdata = newdata)
predict_quiz
fact_olive$Area <- as.factor(olive$Area)
fact_olive <-olive
fact_olive$Area <- as.factor(olive$Area)
model_fit2<- train(Area~., data=fact_olive, method='rpart')
pred_fit2<- predict(model_fit2, newdata = fact_olive)
predict_quiz2<- predict(model_fit2, newdata = newdata)
predict_quiz2
text(model_fit2$finalModel)
plot(model_fit2$finalModel)
text(model_fit2$finalModel)
confusionMatrix(olive$Area, pred_fit$Area)
confusionMatrix(olive$Area, pred_fit)
pred_fit
confusionMatrix(fact_olive$Area, pred_fit2)
View(quiz_data)
plot(model_fit$finalModel)
text(model_fit$finalModel)
install.packages(c("arules", "arulesViz", "corrplot", "graphlayouts", "parallelly", "rio", "rsconnect", "servr", "sf", "slam", "terra", "xgboost", "yardstick"))
install.packages("igraph")
install.packages("memoise")
install.packages("sjPlot")
install.packages("terra")
install.packages("conflicted")
library(ProjectTemplate)
create.project('pratical-machine-learning-project', template = 'minimal', rstudio.project = TRUE)
install.packages(c("credentials", "stringi"))
install.packages("shiny")
install.packages(c("brio", "cpp11", "devtools"))
install.packages(c("emmeans", "fs", "glue", "pkgbuild", "pkgdown", "pkgload"))
install.packages(c("quanteda", "readr", "remotes", "vroom", "withr", "xml2"))
?builder
library(shiny)
?builder
install.packages("miniUI")
source("~/R_projects/developing-data-products/q1_p5/q1_p5.R")
my_data <- data.frame(X = rnorm(100), Y = rnorm(100))
pickXY(my_data)
View(pickXY)
source("~/R_projects/developing-data-products/q1_p5/q1_p5.R")
pickXY(my_data, 'X', 'Y')
source("~/R_projects/developing-data-products/q1_p5/q1_p5.R")
pickXY(my_data, 'X', 'Y')
source("~/R_projects/developing-data-products/q1_p5/q1_p5.R")
pickXY(my_data)
source("~/.active-rstudio-document")
shinyApp(ui, server)
source("~/.active-rstudio-document")
shinyApp(ui, server)
source("~/.active-rstudio-document")
shinyApp(ui, server)
source("~/.active-rstudio-document")
shinyApp(ui, server)
source("~/.active-rstudio-document")
shinyApp(ui, server)
install.packages("pdftools")
shiny::runApp('R_projects/developing-data-products/test_app_1')
runApp('R_projects/developing-data-products/test_app_1')
install.packages("flexdashboard")
runApp('R_projects/developing-data-products/test_app_1')
install.packages("c3")
runApp('R_projects/developing-data-products/test_app_1')
devtools::install_github("FrissAnalytics/shinyJsTutorials/widgets/C3")
library(C3)
runApp('R_projects/developing-data-products/test_app_1')
shiny::runApp('R_projects/developing-data-products/week_04_project')
library(rsconnect)
rsconnect::deployApp('/Users/derhart/R_projects/developing-data-products/week_04_project')
runApp('R_projects/developing-data-products/week_04_project')
install.packages(c("arules", "dtplyr", "fs", "Matrix", "pkgbuild", "pkgdown", "ragg", "raster", "rJava", "RSQLite", "sessioninfo", "sjmisc", "testthat", "TTR", "usethis"))
setwd("~/R_projects/developing-data-products/week_04_project")
library('devtools')
install_github('slidify', 'ramnathv')
install_github('slidify/ramnathv')
install_github('ramnathv/slidify')
install_github('ramnathv/slidifyLibraries')
install_github('ramnathv/slidify',ref='dev')
install.packages("~/Downloads/slidify-master.zip", repos = NULL, type = "win.binary")
install.packages("~/Downloads/slidify-master.zip", repos=NULL, type="source")
install_local("~/Downloads/slidify-master.zip")
install_local("~/Downloads/slidifyLibraries-master.zip")
library(slidify)
?slidify
author('ddp_week_4_project-slidify')
library(slidifyLibraries)
setwd("~/R_projects/developing-data-products/week_04_project/ddp_week_4_project-slidify")
library(here)
